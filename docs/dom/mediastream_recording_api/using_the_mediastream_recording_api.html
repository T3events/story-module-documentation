<h1>MediaStream Recording API: Using the MediaStream Recording API</h1> <div class="summary"> <p><span class="seoSummary">The <a href="../mediastream_recording_api">MediaStream Recording API</a> makes it easy to record audio and/or video streams. When used with <a href="../mediadevices/getusermedia" title="The MediaDevices.getUserMedia() method prompts the user for permission to use one video and/or one audio input device such as a camera or screensharing and/or a microphone. If the user provides permission, then the returned Promise is resolved with the resulting MediaStream object. If the user denies permission, or media is not available, then the promise is rejected with PermissionDeniedError or NotFoundError respectively. Note that it is possible for the returned promise to neither resolve nor reject, as the user is not required to make a choice."><code>navigator.mediaDevices.getUserMedia()</code></a>, it provides an easy way to record from the user's input devices and instantly use the result in web apps. Both audio and video may be recorded, separately or together. This article aims to provide a basic guide on how to use the MediaRecorder interface, which provides this API.</span></p> </div> <h2 id="A_sample_application_Web_Dictaphone">A sample application: Web Dictaphone</h2> <p><img src="https://mdn.mozillademos.org/files/7885/web-dictaphone.png" style="display: block; margin: 0px auto;" alt="An image of the Web dictaphone sample app - a sine wave sound visualization, then record and stop buttons, then an audio jukebox of recorded tracks that can be played back."></p> <p>To demonstrate basic usage of the MediaRecorder API, we have built a web-based dictaphone. It allows you to record snippets of audio and then play them back. It even gives you a visualization of your device's sound input, using the Web Audio API. We'll concentrate on the recording and playback functionality for this article.</p> <p>You can see this <a href="https://mdn.github.io/web-dictaphone/">demo running live</a>, or <a href="https://github.com/mdn/web-dictaphone">grab the source code</a> on Github (<a href="https://github.com/mdn/web-dictaphone/archive/master.zip">direct zip file download</a>.)</p> <h2 id="CSS_goodies">CSS goodies</h2> <p>The HTML is pretty simple in this app, so we won't go through it here; there are a couple of slightly more interesting bits of CSS worth mentioning, however, so we'll discuss them below. If you are not interested in CSS and want to get straight to the JavaScript, skip to the <a href="#Basic_app_setup">Basic app setup</a> section.</p> <h3 id="Keeping_the_interface_constrained_to_the_viewport_regardless_of_device_height_with_calc()">Keeping the interface constrained to the viewport, regardless of device height, with calc()</h3> <p>The <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/calc" title="The calc() CSS function can be used anywhere a &lt;length&gt;, &lt;frequency&gt;, &lt;angle&gt;, &lt;time&gt;, &lt;number&gt;, or &lt;integer&gt; is required. With calc(), you can perform calculations to determine CSS property values."><code>calc()</code></a> function is one of those useful little utility features that's cropped up in CSS that doesn't look like much initially, but soon starts to make you think "Wow, why didn't we have this before? Why was CSS2 layout so awkward?" It allows you do a calculation to determine the computed value of a CSS unit, mixing different units in the process.</p> <p>For example, in Web Dictaphone we have theee main UI areas, stacked vertically. We wanted to give the first two (the header and the controls) fixed heights:</p> <pre data-language="css">header {
  height: 70px;
}

.main-controls {
  padding-bottom: 0.7rem;
  height: 170px;
}</pre> <p>However, we wanted to make the third area (which contains the recorded samples you can play back) take up whatever space is left, regardless of the device height. Flexbox could be the answer here, but it's a bit overkill for such a simple layout. Instead, the problem was solved by making the third container's height equal to 100% of the parent height, minus the heights and padding of the other two:</p> <pre data-language="css">.sound-clips {
  box-shadow: inset 0 3px 4px rgba(0,0,0,0.7);
  background-color: rgba(0,0,0,0.1);
  height: calc(100% - 240px - 0.7rem);
  overflow: scroll;
}</pre> <div class="note"> <p><strong>Note</strong>: <code>calc()</code> has good support across modern browsers too, even going back to Internet Explorer 9.</p> </div> <h3 id="Checkbox_hack_for_showinghiding">Checkbox hack for showing/hiding</h3> <p>This is fairly well documented already, but we thought we'd give a mention to the checkbox hack, which abuses the fact that you can click on the <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/label" title="The HTML Label Element (&lt;label&gt;) represents a caption for an item in a user interface. It can be associated with a control either by placing the control element inside the &lt;label&gt; element, or by using the for attribute. Such a control is called the labeled control of the label element. One input can be associated with multiple labels."><code>&lt;label&gt;</code></a> of a checkbox to toggle it checked/unchecked. In Web Dictaphone this powers the Information screen, which is shown/hidden by clicking the question mark icon in the top right hand corner. First of all, we style the <code>&lt;label&gt;</code> how we want it, making sure that it has enough z-index to always sit above the other elements and therefore be focusable/clickable:</p> <pre data-language="css">label {
    font-family: 'NotoColorEmoji';
    font-size: 3rem;
    position: absolute;
    top: 2px;
    right: 3px;
    z-index: 5;
    cursor: pointer;
}</pre> <p>Then we hide the actual checkbox, because we don't want it cluttering up our UI:</p> <pre data-language="css">input[type=checkbox] {
   position: absolute;
   top: -100px;
}</pre> <p>Next, we style the Information screen (wrapped in an <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/aside" title="The HTML &lt;aside&gt; element represents a section of the page with content connected tangentially to the rest, which could be considered separate from that content. These sections are often represented as sidebars or inserts. They often contain the definitions on the sidebars, such as definitions from the glossary; there may also be other types of information, such as related advertisements; the biography of the author; web applications; profile information or related links on the blog."><code>&lt;aside&gt;</code></a> element) how we want it, give it fixed position so that it doesn't appear in the layout flow and affect the main UI, transform it to the position we want it to sit in by default, and give it a transition for smooth showing/hiding:</p> <pre data-language="css">aside {
   position: fixed;
   top: 0;
   left: 0;
   text-shadow: 1px 1px 1px black;  
   width: 100%;
   height: 100%;
   transform: translateX(100%);
   transition: 0.6s all;
   background-color: #999;
    background-image: linear-gradient(to top right, rgba(0,0,0,0), rgba(0,0,0,0.5));
}</pre> <p>Last, we write a rule to say that when the checkbox is checked (when we click/focus the label), the adjacent <code>&lt;aside&gt;</code> element will have it's horizontal translation value changed and transition smoothly into view:</p> <pre data-language="css">input[type=checkbox]:checked ~ aside {
  transform: translateX(0);
}</pre> <h2 id="Basic_app_setup">Basic app setup</h2> <p>To grab the media stream we want to capture, we use <code>getUserMedia()</code> (<code>gUM</code> for short). We then use the MediaRecorder API to record the stream, and output each recorded snippet into the source of a generated <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/audio" title="The HTML &lt;audio&gt; element is used to embed sound content in documents. It may contain one or more audio sources, represented using the src attribute or the &lt;source&gt; element; the browser will choose the most suitable one."><code>&lt;audio&gt;</code></a> element so it can be played back.</p> <p>First, we'll add in a forking mechanism to make <code>gUM</code> work, regardless of browser prefixes.</p> <pre data-language="js">navigator.getUserMedia = navigator.getUserMedia ||
                         navigator.webkitGetUserMedia ||
                         navigator.mozGetUserMedia;</pre> <p>Then we'll declare some variables for the record and stop buttons, and the <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/article" title="The HTML &lt;article&gt; element represents a self-contained composition in a document, page, application, or site, which is intended to be independently distributable or reusable (e.g., in syndication). This could be a forum post, a magazine or newspaper article, a blog entry, an object, or any other independent item of content. Each &lt;article&gt; should be identified, typically by including a heading (&lt;h1&gt;-&lt;h6&gt; element) as a child of the &lt;article&gt; element."><code>&lt;article&gt;</code></a> that will contain the generated audio players:</p> <pre data-language="js">var record = document.querySelector('.record');
var stop = document.querySelector('.stop');
var soundClips = document.querySelector('.sound-clips');</pre> <p>Finally for this section, we set up the basic <code>gUM</code> structure:</p> <pre data-language="js">if (navigator.getUserMedia) {
   console.log('getUserMedia supported.');
   navigator.getUserMedia (
      // constraints - only audio needed for this app
      {
         audio: true
      },

      // Success callback
      function(stream) {
 
        
      },

      // Error callback
      function(err) {
         console.log('The following gUM error occured: ' + err);
      }
   );
} else {
   console.log('getUserMedia not supported on your browser!');
}</pre> <p>The whole thing is wrapped in a test that checks whether <code>gUM</code> is supported before running anything else. Next, we call <code>getUserMedia()</code> and inside it define:</p> <ul> <li>
<strong>The constraints</strong>: Only audio is to be captured for our dictaphone.</li> <li>
<strong>The success callback</strong>: This code is run once the <code>gUM</code> call has been completed successfully.</li> <li>
<strong>The error/failure callback</strong>: The code is run if the <code>gUM</code> call fails for whatever reason.</li> </ul> <div class="note"> <p><strong>Note</strong>: All of the code below is placed inside the gUM success callback.</p> </div> <h2 id="Capturing_the_media_stream">Capturing the media stream</h2> <p>Once <code>gUM</code> has created a media stream successfully, you create a new Media Recorder instance with the <code>MediaRecorder()</code> constructor and pass it the stream directly. This is your entry point into using the MediaRecorder API — the stream is now ready to be captured into a <a href="../blob" title="Technical review completed."><code>Blob</code></a>, in the default encoding format of your browser.</p> <pre data-language="js">var mediaRecorder = new MediaRecorder(stream);</pre> <p>There are a series of methods available in the <a href="../mediarecorder" title="The MediaRecorder interface of the MediaStream Recording API provides functionality to easily record media. It is created by the invocation of the MediaRecorder() constructor."><code>MediaRecorder</code></a> interface that allow you to control recording of the media stream; in Web Dictaphone we just make use of two, and listen to some events. First of all, <a href="../mediarecorder/start" title="The MediaRecorder.start() method (part of the MediaRecorder API) is used to start capturing media into a Blob."><code>MediaRecorder.start()</code></a> is used to start recording the stream once the record button is pressed:</p> <pre data-language="js">record.onclick = function() {
  mediaRecorder.start();
  console.log(mediaRecorder.state);
  console.log("recorder started");
  record.style.background = "red";
  record.style.color = "black";
}</pre> <p>When the MediaRecorder is recording, the <a href="../mediarecorder/state" title="The MediaRecorder.state read-only property returns the current state of the current MediaRecorder object."><code>MediaRecorder.state</code></a> property will return a value of "recording".</p> <p>As recording progresses, we need to collect the audio data. We register an event handler to do this using <a href="../mediarecorder/ondataavailable" title="The MediaRecorder.ondataavailable event handler (part of the MediaStream Recording API) handles the dataavailable event, letting you run code in response to Blob data being made available for use."><code>mediaRecorder.ondataavailable</code></a>:</p> <pre data-language="js">var chunks = [];

mediaRecorder.ondataavailable = function(e) {
  <span class="pl-smi">chunks</span>.<span class="pl-c1">push</span>(<span class="pl-smi">e</span>.<span class="pl-c1">data</span>);
}</pre> <p>The browser will fire <code>dataavailable</code> events as needed, but you can also include a timeslice when invoking the <code>start()</code> method — for example <code>start(10000)</code> — to control this interval, or call <a href="../mediarecorder/requestdata" title="The MediaRecorder.requestData() method (part of the MediaRecorder API) is used to raise a dataavailable event containing a Blob object of the captured media as it was when the method was called."><code>MediaRecorder.requestData()</code></a> to trigger an event when you need it.</p> <p>Lastly, we use the <a href="../mediarecorder/stop" title="The MediaRecorder.stop() method (part of the MediaRecorder API) is used to stop media capture."><code>MediaRecorder.stop()</code></a> method to stop the recording when the stop button is pressed, and finalize the <a href="../blob" title="Technical review completed."><code>Blob</code></a> ready for use somewhere else in our application.</p> <pre data-language="js">stop.onclick = function() {
  mediaRecorder.stop();
  console.log(mediaRecorder.state);
  console.log("recorder stopped");
  record.style.background = "";
  record.style.color = "";
}</pre> <p>Note that the recording may also stop naturally if the media stream ends (e.g. if you were grabbing a song track and the track ended, or the user stopped sharing their microphone).</p> <h2 id="Grabbing_and_using_the_blob">Grabbing and using the blob</h2> <p>When recording has stopped, the <code>state</code> property returns a value of "inactive", and a stop event is fired. We register an event handler for this using <a href="../mediarecorder/onstop" title="The MediaRecorder.onstop event handler (part of the MediaRecorder API) handles the stop event, allowing you to run code in response to media recording via a MediaRecorder being stopped."><code>mediaRecorder.onstop</code></a>, and finalize our blob there from all the chunks we have received:</p> <pre data-language="js">mediaRecorder.onstop = function(e) {
  console.log("recorder stopped");

  var clipName = prompt('Enter a name for your sound clip');

  var clipContainer = document.createElement('article');
  var clipLabel = document.createElement('p');
  var audio = document.createElement('audio');
  var deleteButton = document.createElement('button');
           
  clipContainer.classList.add('clip');
  audio.setAttribute('controls', '');
  deleteButton.innerHTML = "Delete";
  clipLabel.innerHTML = clipName;

  clipContainer.appendChild(audio);
  clipContainer.appendChild(clipLabel);
  clipContainer.appendChild(deleteButton);
  soundClips.appendChild(clipContainer);

  var blob = new Blob(chunks, { 'type' : 'audio/ogg; codecs=opus' });
  chunks = [];
  var audioURL = window.URL.createObjectURL(blob);
  audio.src = audioURL;

  deleteButton.onclick = function(e) {
    var evtTgt = e.target;
    evtTgt.parentNode.parentNode.removeChild(evtTgt.parentNode);
  }
}</pre> <p>Let's go through the above code and look at what's happening.</p> <p>First, we display a prompt asking the user to name their clip.</p> <p>Next, we create an HTML structure like the following, inserting it into our clip container, which is a <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/section" title="The HTML &lt;section&gt; element represents a generic section of a document, i.e., a thematic grouping of content, typically with a heading. Each &lt;section&gt; should be identified, typically by including a heading (&lt;h1&gt;-&lt;h6&gt; element) as a child of the &lt;section&gt; element."><code>&lt;section&gt;</code></a> element.</p> <pre data-language="html">&lt;article class="clip"&gt;
  &lt;audio controls&gt;&lt;/audio&gt;
  &lt;p&gt;<em>your clip name</em>&lt;/p&gt;
  &lt;button&gt;Delete&lt;/button&gt;
&lt;/article&gt;</pre> <p>After that, we create a combined <a href="../blob" title="Technical review completed."><code>Blob</code></a> out of the recorded audio chunks, and create an object URL pointing to it, using <code>window.URL.createObjectURL(blob)</code>. We then set the value of the <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/audio" title="The HTML &lt;audio&gt; element is used to embed sound content in documents. It may contain one or more audio sources, represented using the src attribute or the &lt;source&gt; element; the browser will choose the most suitable one."><code>&lt;audio&gt;</code></a> element's <code><a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/audio#attr-src">src</a></code> attribute to the object URL, so that when the play button is pressed on the audio player, it will play the <code>Blob</code>.</p> <p>Finally, we set an <code>onclick</code> handler on the delete button to be a function that deletes the whole clip HTML structure.</p> <h2 id="Specifications">Specifications</h2> <table class="standard-table"> <tbody> <tr> <th scope="col">Specification</th> <th scope="col">Status</th> <th scope="col">Comment</th> </tr> <tr> <td><a href="https://w3c.github.io/mediacapture-record/MediaRecorder.html#MediaRecorderAPI" class="external" lang="en" title="The 'MediaStream Recording' specification" hreflang="en">MediaStream Recording</a></td> <td><span class="spec-WD">Working Draft</span></td> <td>Initial definition</td> </tr> </tbody> </table> <h2 id="Browser_compatibility">Browser compatibility</h2>  <div id="compat-desktop"> <table class="compat-table"> <tbody> <tr> <th>Feature</th> <th>Chrome</th> <th>Firefox (Gecko)</th> <th>Internet Explorer</th> <th>Opera</th> <th>Safari (WebKit)</th> </tr> <tr> <td>Basic support</td> <td>47</td> <td>
<a href="https://developer.mozilla.org/en-US/Firefox/Releases/25" title="Released on 2013-10-29.">25.0</a> (25.0)</td> <td><span style="color: #f00;">No support</span></td> <td><span style="color: #f00;">No support</span></td> <td><span style="color: #f00;">No support</span></td> </tr> </tbody> </table> </div> <div id="compat-mobile"> <table class="compat-table"> <tbody> <tr> <th>Feature</th> <th>Android</th> <th>Android Webview</th> <th>Firefox Mobile (Gecko)</th> <th>Firefox OS</th> <th>IE Phone</th> <th>Opera Mobile</th> <th>Safari Mobile</th> <th>Chrome Mobile</th> </tr> <tr> <td>Basic support</td> <td><span style="color: #f00;">No support</span></td> <td>47</td> <td>
<a href="https://developer.mozilla.org/en-US/Firefox/Releases/25" title="Released on 2013-10-29.">25.0</a> (25.0)</td> <td>1.3<sup>[1]</sup>
</td> <td><span style="color: #f00;">No support</span></td> <td><span style="color: #f00;">No support</span></td> <td><span style="color: #f00;">No support</span></td> <td>47</td> </tr> </tbody> </table> </div> <p>[1] The initial Firefox OS implementation only supported audio recording.</p> <h2 id="See_also">See also</h2> <ul> <li>
<a href="../mediastream_recording_api">MediaRecorder API</a> landing page</li> <li><code><a href="https://developer.mozilla.org/en-US/docs/Web/API/navigator/getUserMedia" title="The Navigator.getUserMedia() method prompts the user for permission to use up to one video input device (such as a camera or shared screen) and up to one audio input device (such as a microphone). If permission is granted, a MediaStream whose video and/or audio tracks come from those devices is delivered to the specified success callback. If permission is denied, no compatible input devices exist, or any other error condition occurs, the error callback is executed with a MediaStreamError object describing what went wrong. If the user instead doesn't make a choice at all, neither callback is executed."><code>Navigator.getUserMedia()</code></a></code></li> <li><a href="https://addpipe.com/blog/media-recorder-api-is-now-supported-by-65-of-all-desktop-internet-users/">MediaRecorder API now supported by 65% of your website users</a></li> </ul><div class="_attribution">
  <p class="_attribution-p">
    <a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaStream_Recording_API/Using_the_MediaStream_Recording_API$edit" class="_attribution-link">Edit this page on MDN</a>
  </p>
</div>
<div class="_attribution">
  <p class="_attribution-p">
    &copy; 2005&ndash;2017 Mozilla Developer Network and individual contributors.<br>Licensed under the Creative Commons Attribution-ShareAlike License v2.5 or later.<br>
    <a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaStream_Recording_API/Using_the_MediaStream_Recording_API" class="_attribution-link">https://developer.mozilla.org/en-US/docs/Web/API/MediaStream_Recording_API/Using_the_MediaStream_Recording_API</a>
  </p>
</div>
