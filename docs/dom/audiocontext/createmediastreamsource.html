<h1>AudioContext.createMediaStreamSource</h1> <div> <p>The <code>createMediaStreamSource()</code> method of the <a title="An AudioContext can be a target of events, therefore it implements the EventTarget interface." href="../audiocontext"><code>AudioContext</code></a> Interface is used to create a new <a title="A MediaElementSourceNode has no inputs and exactly one output, and is created using the AudioContext.createMediaStreamSource method. The amount of channels in the output equals the number of channels in AudioMediaStreamTrack. If there is no valid media stream, then the number of output channels will be one silent channel." href="../mediastreamaudiosourcenode"><code>MediaStreamAudioSourceNode</code></a> object, given a media stream (say, from a <a title="The Navigator.getUserMedia() method prompts the user for permission to use up to one video input device (such as a camera or shared screen) and up to one audio input device (such as a microphone). If permission is granted, a MediaStream whose video and/or audio tracks come from those devices is delivered to the specified success callback. If permission is denied, no compatible input devices exist, or any other error condition occurs, the error callback is executed with a MediaStreamError object describing what went wrong. If the user instead doesn't make a choice at all, neither callback is executed." href="https://developer.mozilla.org/en-US/docs/Web/API/navigator/getUserMedia"><code>navigator.getUserMedia</code></a> instance), the audio from which can then be played and manipulated.</p> </div> <p>For more details about media stream audio source nodes, check out the <a title="A MediaElementSourceNode has no inputs and exactly one output, and is created using the AudioContext.createMediaStreamSource method. The amount of channels in the output equals the number of channels in AudioMediaStreamTrack. If there is no valid media stream, then the number of output channels will be one silent channel." href="../mediastreamaudiosourcenode"><code>MediaStreamAudioSourceNode</code></a> reference page.</p> <h2 id="Syntax">Syntax</h2> <pre data-language="js">var audioCtx = new AudioContext();
var source = audioCtx.createMediaStreamSource(stream);</pre> <h3 id="Parameters">Parameters</h3> <dl> <dt>stream</dt> <dd>A <a title="The MediaStream interface represents a stream of media content. A stream consists of several tracks such as video or audio tracks. Each track is specified as an instance of MediaStreamTrack." href="../mediastream"><code>MediaStream</code></a> object that you want to feed into an audio processing graph to manipulate.</dd> </dl> <h3 id="Returns">Returns</h3> <p>A <a title="A MediaElementSourceNode has no inputs and exactly one output, and is created using the AudioContext.createMediaStreamSource method. The amount of channels in the output equals the number of channels in AudioMediaStreamTrack. If there is no valid media stream, then the number of output channels will be one silent channel." href="../mediastreamaudiosourcenode"><code>MediaStreamAudioSourceNode</code></a>.</p> <h2 id="Example">Example</h2> <p>In this example, we grab a media (audio + video) stream from <a title="The Navigator.getUserMedia() method prompts the user for permission to use up to one video input device (such as a camera or shared screen) and up to one audio input device (such as a microphone). If permission is granted, a MediaStream whose video and/or audio tracks come from those devices is delivered to the specified success callback. If permission is denied, no compatible input devices exist, or any other error condition occurs, the error callback is executed with a MediaStreamError object describing what went wrong. If the user instead doesn't make a choice at all, neither callback is executed." href="https://developer.mozilla.org/en-US/docs/Web/API/navigator/getUserMedia"><code>navigator.getUserMedia</code></a>, feed the media into a <a title="Use the HTML &lt;video&gt; element to embed video content in a document." href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/video"><code>&lt;video&gt;</code></a> element to play then mute the audio, but then also feed the audio into a <a title="A MediaElementSourceNode has no inputs and exactly one output, and is created using the AudioContext.createMediaStreamSource method. The amount of channels in the output equals the number of channels in AudioMediaStreamTrack. If there is no valid media stream, then the number of output channels will be one silent channel." href="../mediastreamaudiosourcenode"><code>MediaStreamAudioSourceNode</code></a>. Next, we feed this source audio into a low pass <a title="The BiquadFilterNode interface represents a simple low-order filter, and is created using the AudioContext.createBiquadFilter() method. It is an AudioNode that can represent different kinds of filters, tone control devices, and graphic equalizers." href="../biquadfilternode"><code>BiquadFilterNode</code></a> (which effectively serves as a bass booster), then a <a title="AudioDestinationNode has no output (as it is the output, no more AudioNode can be linked after it in the audio graph) and one input. The amount of channels in the input must be between 0 and the maxChannelCount value or an exception is raised." href="../audiodestinationnode"><code>AudioDestinationNode</code></a>.</p> <p>The range slider below the <a title="Use the HTML &lt;video&gt; element to embed video content in a document." href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/video"><code>&lt;video&gt;</code></a> element controls the amount of gain given to the lowpass filter — increase the value of the slider to make the audio sound more bass heavy!</p> <div class="note"> <p><strong>Note</strong>: You can see this <a href="https://mdn.github.io/webaudio-examples/stream-source-buffer/">example running live</a>, or <a href="https://github.com/mdn/webaudio-examples/tree/master/stream-source-buffer">view the source</a>.</p> </div> <pre data-language="js">var pre = document.querySelector('pre');
var video = document.querySelector('video');
var myScript = document.querySelector('script');
var range = document.querySelector('input');

// getUserMedia block - grab stream
// put it into a MediaStreamAudioSourceNode
// also output the visuals into a video element

if (navigator.mediaDevices) {
    console.log('getUserMedia supported.');
    navigator.mediaDevices.getUserMedia ({audio: true, video: true})
    .then(function(stream) {
        video.srcObject = stream;
        video.onloadedmetadata = function(e) {
            video.play();
            video.muted = true;
        };

        // Create a MediaStreamAudioSourceNode
        // Feed the HTMLMediaElement into it
        var audioCtx = new AudioContext();
        var source = audioCtx.createMediaStreamSource(stream);

        // Create a biquadfilter
        var biquadFilter = audioCtx.createBiquadFilter();
        biquadFilter.type = "lowshelf";
        biquadFilter.frequency.value = 1000;
        biquadFilter.gain.value = range.value;

        // connect the AudioBufferSourceNode to the gainNode
        // and the gainNode to the destination, so we can play the
        // music and adjust the volume using the mouse cursor
        source.connect(biquadFilter);
        biquadFilter.connect(audioCtx.destination);

        // Get new mouse pointer coordinates when mouse is moved
        // then set new gain value

        range.oninput = function() {
            biquadFilter.gain.value = range.value;
        }
    })
    .catch(function(err) {
        console.log('The following gUM error occured: ' + err);
    });
} else {
   console.log('getUserMedia not supported on your browser!');
}

// dump script to pre element

pre.innerHTML = myScript.innerHTML;</pre> <div class="note"> <p><strong>Note</strong>: As a consequence of calling <code>createMediaStreamSource()</code>, audio playback from the media stream will be re-routed into the processing graph of the AudioContext. So playing/pausing the stream can still be done through the media element API and the player controls.</p> </div>  <h2 id="Specifications">Specifications</h2> <table class="standard-table"> <tbody> <tr> <th scope="col">Specification</th> <th scope="col">Status</th> <th scope="col">Comment</th> </tr> <tr> <td><a hreflang="en" class="external" lang="en" href="https://webaudio.github.io/web-audio-api/#widl-AudioContext-createMediaStreamSource-MediaStreamAudioSourceNode-MediaStream-mediaStream">Web Audio API<br><small lang="en-US">The definition of 'createMediaStreamSource()' in that specification.</small></a></td> <td><span class="spec-WD">Working Draft</span></td> <td> </td> </tr> </tbody> </table> <h2 id="Browser_compatibility">Browser compatibility</h2>  <div id="compat-desktop"> <table class="compat-table"> <tbody> <tr> <th>Feature</th> <th>Chrome</th> <th>Edge</th> <th>Firefox (Gecko)</th> <th>Internet Explorer</th> <th>Opera</th> <th>Safari (WebKit)</th> </tr> <tr> <td>Basic support</td> <td>10.0<span title="prefix" class="inlineIndicator prefixBox prefixBoxInline"><a title="The name of this feature is prefixed with 'webkit' as this browser considers it experimental" href="https://developer.mozilla.org/en-US/docs/Web/Guide/Prefixes">webkit</a></span>
</td> <td><span title="Please update this with the earliest version of support." style="color: #888;">(Yes)</span></td> <td>
<a title="Released on 2013-10-29." href="https://developer.mozilla.org/en-US/Firefox/Releases/25">25.0</a> (25.0) </td> <td><span style="color: #f00;">No support</span></td> <td>15.0<span title="prefix" class="inlineIndicator prefixBox prefixBoxInline"><a title="The name of this feature is prefixed with 'webkit' as this browser considers it experimental" href="https://developer.mozilla.org/en-US/docs/Web/Guide/Prefixes">webkit</a></span><br> 22 (unprefixed)</td> <td>6.0<span title="prefix" class="inlineIndicator prefixBox prefixBoxInline"><a title="The name of this feature is prefixed with 'webkit' as this browser considers it experimental" href="https://developer.mozilla.org/en-US/docs/Web/Guide/Prefixes">webkit</a></span>
</td> </tr> </tbody> </table> </div> <div id="compat-mobile"> <table class="compat-table"> <tbody> <tr> <th>Feature</th> <th>Android</th> <th>Edge</th> <th>Firefox Mobile (Gecko)</th> <th>Firefox OS</th> <th>IE Mobile</th> <th>Opera Mobile</th> <th>Safari Mobile</th> <th>Chrome for Android</th> </tr> <tr> <td>Basic support</td> <td><span title="Compatibility unknown; please update this." style="color: rgb(255, 153, 0);">?</span></td> <td><span title="Please update this with the earliest version of support." style="color: #888;">(Yes)</span></td> <td>26.0</td> <td>1.2</td> <td><span title="Compatibility unknown; please update this." style="color: rgb(255, 153, 0);">?</span></td> <td><span title="Compatibility unknown; please update this." style="color: rgb(255, 153, 0);">?</span></td> <td><span title="Compatibility unknown; please update this." style="color: rgb(255, 153, 0);">?</span></td> <td>33.0</td> </tr> </tbody> </table> </div> <h2 id="See_also">See also</h2> <ul> <li><a href="https://developer.mozilla.org/en-US/docs/Web_Audio_API/Using_Web_Audio_API">Using the Web Audio API</a></li> </ul><div class="_attribution">
  <p class="_attribution-p">
    <a href="https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createMediaStreamSource$edit" class="_attribution-link">Edit this page on MDN</a>
  </p>
</div>
<div class="_attribution">
  <p class="_attribution-p">
    &copy; 2005&ndash;2017 Mozilla Developer Network and individual contributors.<br>Licensed under the Creative Commons Attribution-ShareAlike License v2.5 or later.<br>
    <a href="https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createMediaStreamSource" class="_attribution-link">https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createMediaStreamSource</a>
  </p>
</div>
