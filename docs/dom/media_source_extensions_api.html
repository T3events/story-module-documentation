<h1>Media Source Extensions API</h1><div class="notice experimental"> <p> <strong>This is an experimental technology</strong><br>Because this technology's specification has not stabilized, check the <a href="#Browser_compatibility">compatibility table</a> for usage in various browsers. Also note that the syntax and behavior of an experimental technology is subject to change in future versions of browsers as the specification changes.</p> </div> <p><span class="seoSummary">The Media Source Extensions API (MSE) provides functionality enabling plugin-free web-based streaming media. Using MSE, media streams can be created via JavaScript, and played using <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/audio" title="The HTML &lt;audio&gt; element is used to embed sound content in documents. It may contain one or more audio sources, represented using the src attribute or the &lt;source&gt; element; the browser will choose the most suitable one."><code>&lt;audio&gt;</code></a> and <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/video" title="Use the HTML &lt;video&gt; element to embed video content in a document."><code>&lt;video&gt;</code></a> elements.</span></p> <h2 id="Concepts_and_usage">Concepts and usage</h2> <p>Playing video and audio has been available in web applications without plugins for a few years now, but the basic features offered have only really only been useful for playing single whole tracks. We can't, for example, combine/split arraybuffers. Streaming media has up until recently been the domain of Flash, with technologies like Flash Media Server serving video streams using the RTMP protocol.</p> <h3 id="The_MSE_standard">The MSE standard</h3> <p>With Media Source Extensions (MSE), this is changing. MSE allows us to replace the usual single track <code>src</code> value fed to media elements with a reference to a <code>MediaSource</code> object, which is a container for information like the ready state of the media for being played, and references to multiple <code>SourceBuffer</code> objects that represent the different chunks of media that make up the entire stream. MSE gives us finer grained control over how much and how often content is fetched, and some control over memory usage details, such as when buffers are evicted. It lays the groundwork for adaptive bitrate streaming clients (such as those using DASH or HLS) to be built on its extensible API.</p> <p>Creating assets that work with MSE in modern browsers is a laborious process, taking both significant time, computing power, and energy. The usage of external utilities to massage the content into a suitable format is required. While browser support for the various media containers with MSE is spotty, usage of the H.264 video codec, AAC audio codec, and MP4 container format is a common baseline. MSE also provides an API for runtime detection of container and codec support.</p> <p>If you do not require explicit control of video quality over time, the rate at which content is fetched, or the rate at which memory is evicted, then the <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/video" title="Use the HTML &lt;video&gt; element to embed video content in a document."><code>&lt;video&gt;</code></a> and <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/source" title="The HTML &lt;source&gt; element specifies multiple media resources for either the &lt;picture&gt;, the &lt;audio&gt; or the &lt;video&gt; element. It is an empty element. It is commonly used to serve the same media content in multiple formats supported by different browsers."><code>&lt;source&gt;</code></a> tags may well be a simple and adequate solution.</p> <h3 id="DASH">DASH</h3> <p>Dynamic Adaptive Streaming over HTTP (DASH) is a protocol for specifying how adaptive content should be fetched. It is effectively a layer built on top of MSE for building adaptive bitrate streaming clients. While there are other protocols available (such as HTTP Live Streaming (HLS)), DASH has the most platform support.</p> <p>DASH moves lots of logic out of the network protocol and into the client side application logic, using the simpler HTTP protocol to fetch files. Indeed, one can support DASH with a simple static file server, which is also great for CDNs. This is in direct contrast with previous streaming solutions that required expensive licenses for propriety non-standard client/server protocol implementations.</p> <p>The two most common use cases for DASH involve watching content “on demand” or “live.” On demand allows a developer to take their time transcoding the assets into multiple resolutions of various quality.</p> <p>Live profile content can introduce latency due to its transcoding and broadcasting, so DASH is not suitable for real time communication like <a href="webrtc_api">WebRTC</a> is. It can however support significantly more client connections than WebRTC.</p> <p>There are numerous available free and open source tools for transcoding content and preparing it for use with DASH, DASH file servers, and DASH client libraries written in JavaScript.</p> <h2 id="Media_Source_Extensions_Interfaces">Media Source Extensions Interfaces</h2> <dl> <dt><a href="mediasource" title="The MediaSource interface represents a source of media data for an HTMLMediaElement object. A MediaSource object can be attached to a HTMLMediaElement to be played in the user agent."><code>MediaSource</code></a></dt> <dd>Represents a media source to be played via an <a href="htmlmediaelement" title="The HTMLMediaElement interface adds to HTMLElement the properties and methods needed to support basic media-related capabilities that are common to audio and video. The HTMLVideoElement and HTMLAudioElement elements both inherit this interface."><code>HTMLMediaElement</code></a> object.</dd> <dt><a href="sourcebuffer" title="The SourceBuffer interface represents a chunk of media to be passed into an HTMLMediaElement and played, via a MediaSource object. This can be made up of one or several media segments."><code>SourceBuffer</code></a></dt> <dd>Represents a chunk of media to be passed into an <a href="htmlmediaelement" title="The HTMLMediaElement interface adds to HTMLElement the properties and methods needed to support basic media-related capabilities that are common to audio and video. The HTMLVideoElement and HTMLAudioElement elements both inherit this interface."><code>HTMLMediaElement</code></a> via a <code>MediaSource</code> object.</dd> <dt><a href="sourcebufferlist" title="The SourceBufferList interface represents a simple container list for multiple SourceBuffer objects."><code>SourceBufferList</code></a></dt> <dd>A simple container list for multiple <code>SourceBuffer</code> objects.</dd> <dt><a href="videoplaybackquality" title="The VideoPlaybackQuality interface represents the set of metrics describing the playback quality of a video."><code>VideoPlaybackQuality</code></a></dt> <dd>Contains information about the quality of video being played by a <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/video" title="Use the HTML &lt;video&gt; element to embed video content in a document."><code>&lt;video&gt;</code></a> element, such as number of dropped or corrupted frames. Returned by the <a href="htmlvideoelement/getvideoplaybackquality" title="The HTMLVideoElement.getVideoPlaybackQuality() creates and returns a VideoPlaybackQuality object containing metrics about the current quality of the video restitution."><code>HTMLVideoElement.getVideoPlaybackQuality()</code></a> method.</dd> <dt><a href="trackdefault" title="The TrackDefault interface provides a SourceBuffer with kind, label, and language information for tracks that do not contain this information in the initialization segments of a media chunk."><code>TrackDefault</code></a></dt> <dd>Provides a <a href="sourcebuffer" title="The SourceBuffer interface represents a chunk of media to be passed into an HTMLMediaElement and played, via a MediaSource object. This can be made up of one or several media segments."><code>SourceBuffer</code></a> with kind, label, and language information for tracks that do not contain this information in the <a href="http://w3c.github.io/media-source/#init-segment">initialization segments</a> of a media chunk.</dd> <dt><a href="trackdefaultlist" title="The TrackDefaultList interface represents a simple container list for multiple TrackDefault objects."><code>TrackDefaultList</code></a></dt> <dd>A simple container list for multiple <code>TrackDefault</code> objects.</dd> </dl> <h2 id="Extensions_to_other_interfaces">Extensions to other interfaces</h2> <dl> <dt><a href="url/createobjecturl" title="The URL.createObjectURL() static method creates a DOMString containing an URL representing the object given in parameter. The URL lifetime is tied to the document in the window on which it was created. The new object URL represents the specified File object or Blob object."><code>URL.createObjectURL()</code></a></dt> <dd>Creates an object URL pointing to a <code>MediaSource</code> object that can then be specified as the <code>src</code> value of an HTML media element to play a media stream.</dd> <dt><a href="htmlmediaelement/seekable" title="The seekable read-only property of the HTMLMediaElement returns a TimeRanges object that contains the time ranges that the user is able to seek to, if any."><code>HTMLMediaElement.seekable</code></a></dt> <dd>When a <code>MediaSource</code> object is played by an HTML media element, this property will return a <a href="timeranges" title="The TimeRanges interface is used to represent a set of time ranges, primarily for the purpose of tracking which portions of media have been buffered when loading it for use by the &lt;audio&gt; and &lt;video&gt; elements."><code>TimeRanges</code></a> object that contains the time ranges that the user is able to seek to.</dd> <dt><a href="htmlvideoelement/getvideoplaybackquality" title="The HTMLVideoElement.getVideoPlaybackQuality() creates and returns a VideoPlaybackQuality object containing metrics about the current quality of the video restitution."><code>HTMLVideoElement.getVideoPlaybackQuality()</code></a></dt> <dd>Returns a <a href="videoplaybackquality" title="The VideoPlaybackQuality interface represents the set of metrics describing the playback quality of a video."><code>VideoPlaybackQuality</code></a> object for the currently played video.</dd> <dt>
<a href="https://developer.mozilla.org/en-US/docs/Web/API/AudioTrack/sourceBuffer" title="The documentation about this has not yet been written; please consider contributing!"><code>AudioTrack.sourceBuffer</code></a>, <a href="https://developer.mozilla.org/en-US/docs/Web/API/VideoTrack/sourceBuffer" title="The documentation about this has not yet been written; please consider contributing!"><code>VideoTrack.sourceBuffer</code></a>, <a href="https://developer.mozilla.org/en-US/docs/Web/API/TextTrack/sourceBuffer" title="The documentation about this has not yet been written; please consider contributing!"><code>TextTrack.sourceBuffer</code></a>
</dt> <dd>Returns the <a href="sourcebuffer" title="The SourceBuffer interface represents a chunk of media to be passed into an HTMLMediaElement and played, via a MediaSource object. This can be made up of one or several media segments."><code>SourceBuffer</code></a> that created the track in question.</dd> </dl> <h2 id="Specifications">Specifications</h2> <table class="standard-table"> <tbody> <tr> <th scope="col">Specification</th> <th scope="col">Status</th> <th scope="col">Comment</th> </tr> <tr> <td><a href="https://w3c.github.io/media-source/" class="external" lang="en" hreflang="en" title="The 'Media Source Extensions' specification">Media Source Extensions</a></td> <td><span class="spec-CR">Candidate Recommendation</span></td> <td>Initial definition.</td> </tr> </tbody> </table> <h2 id="Browser_compatibility">Browser compatibility</h2>  <div id="compat-desktop"> <table class="compat-table"> <tbody> <tr> <th>Feature</th> <th>Chrome</th> <th>Firefox (Gecko)</th> <th>Internet Explorer</th> <th>Opera</th> <th>Safari (WebKit)</th> </tr> <tr> <td>Basic support</td> <td>23</td> <td>
<a href="https://developer.mozilla.org/en-US/Firefox/Releases/25" title="Released on 2013-10-29.">25.0</a> (25.0)<sup>[1]</sup><br> <a href="https://developer.mozilla.org/en-US/Firefox/Releases/42" title="Released on 2015-11-03.">42.0</a> (42.0)</td> <td>11<sup>[2]</sup>
</td> <td>15</td> <td>8</td> </tr> </tbody> </table> </div> <div id="compat-mobile"> <table class="compat-table"> <tbody> <tr> <th>Feature</th> <th>Android</th> <th>Firefox Mobile (Gecko)</th> <th>Firefox OS (Gecko)</th> <th>IE Phone</th> <th>Opera Mobile</th> <th>Safari Mobile</th> </tr> <tr> <td>Basic support</td> <td>4.4.4</td> <td> <p><span style="color: #f00;">No support</span></p> </td> <td><span style="color: #f00;">No support</span></td> <td>11</td> <td>30</td> <td><span style="color: #f00;">No support</span></td> </tr> </tbody> </table> </div> <p>[1] Available after switching the <code>about:config</code> preference <code>media.mediasource.enabled</code> to <code>true</code>. In addition, support was limited to a whitelist of sites, for example YouTube, Netflix, and other popular streaming sites. The whitelist was removed and Media Source Extensions was enabled by default in 42+ for all sites.</p> <p>[2] Only works on Windows 8+.</p> <h2 id="See_also">See also</h2> <ul> <li><a href="media_source_extensions_api/transcoding_assets_for_mse">Transcoding assets for Media Source Extensions</a></li> <li>Using MSE to create a basic streaming service (TBD)</li> <li>Using MPEG DASH to create a streaming application (TBD)</li> <li>The <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/audio" title="The HTML &lt;audio&gt; element is used to embed sound content in documents. It may contain one or more audio sources, represented using the src attribute or the &lt;source&gt; element; the browser will choose the most suitable one."><code>&lt;audio&gt;</code></a> and <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/video" title="Use the HTML &lt;video&gt; element to embed video content in a document."><code>&lt;video&gt;</code></a> elements.</li> <li>
<a href="htmlmediaelement" title="The HTMLMediaElement interface adds to HTMLElement the properties and methods needed to support basic media-related capabilities that are common to audio and video. The HTMLVideoElement and HTMLAudioElement elements both inherit this interface."><code>HTMLMediaElement</code></a>, <a href="htmlvideoelement" title="The HTMLVideoElement interface provides special properties and methods for manipulating video objects. It also inherits properties and methods of HTMLMediaElement and HTMLElement."><code>HTMLVideoElement</code></a>, <a href="htmlaudioelement" title="The HTMLAudioElement interface provides access to the properties of &lt;audio&gt; elements, as well as methods to manipulate them. It derives from the HTMLMediaElement interface."><code>HTMLAudioElement</code></a>.</li> </ul><div class="_attribution">
  <p class="_attribution-p">
    <a href="https://developer.mozilla.org/en-US/docs/Web/API/Media_Source_Extensions_API$edit" class="_attribution-link">Edit this page on MDN</a>
  </p>
</div>
<div class="_attribution">
  <p class="_attribution-p">
    &copy; 2005&ndash;2017 Mozilla Developer Network and individual contributors.<br>Licensed under the Creative Commons Attribution-ShareAlike License v2.5 or later.<br>
    <a href="https://developer.mozilla.org/en-US/docs/Web/API/Media_Source_Extensions_API" class="_attribution-link">https://developer.mozilla.org/en-US/docs/Web/API/Media_Source_Extensions_API</a>
  </p>
</div>
