<h1>OfflineAudioContext</h1> <p>The <code>OfflineAudioContext</code> interface is an <a title="An AudioContext can be a target of events, therefore it implements the EventTarget interface." href="audiocontext"><code>AudioContext</code></a> interface representing an audio-processing graph built from linked together <a title="The AudioNode interface is a generic interface for representing an audio processing module like an audio source (e.g. an HTML &lt;audio&gt; or &lt;video&gt; element, an OscillatorNode, etc.), the audio destination, intermediate processing module (e.g. a filter like BiquadFilterNode or ConvolverNode), or volume control (like GainNode)." href="audionode"><code>AudioNode</code></a>s. In contrast with a standard <a title="An AudioContext can be a target of events, therefore it implements the EventTarget interface." href="audiocontext"><code>AudioContext</code></a>, an <code>OfflineAudioContext</code> doesn't render the audio to the device hardware; instead, it generates it, as fast as it can, and outputs the result to an <a title="Objects of these types are designed to hold small audio snippets, typically less than 45 s. For longer sounds, objects implementing the MediaElementAudioSourceNode are more suitable. The buffer contains data in the following format:  non-interleaved IEEE754 32-bit linear PCM with a nominal range between -1 and +1, that is, 32bits floating point buffer, with each samples between -1.0 and 1.0. If the AudioBuffer has multiple channels, they are stored in separate buffer." href="audiobuffer"><code>AudioBuffer</code></a>.</p> <h2 id="Constructor">Constructor</h2> <dl> <dt><a title="The OfflineAudioContext() constructor creates a new OfflineAudioContext object instance." href="offlineaudiocontext/offlineaudiocontext"><code>OfflineAudioContext.OfflineAudioContext()</code></a></dt> <dd>Creates a new <code>OfflineAudioContext</code> instance.</dd> </dl> <h2 id="Properties">Properties</h2> <p><em>Implements properties from its parent, <a title="An AudioContext can be a target of events, therefore it implements the EventTarget interface." href="audiocontext"><code>AudioContext</code></a>.</em></p> <dl> <dt>
<a title="The length property of the OfflineAudioContext interface returns an integer representing the size of the buffer in sample-frames." href="offlineaudiocontext/length"><code>OfflineAudioContext.length</code></a> <span title="This value may not be changed." class="inlineIndicator readOnly readOnlyInline">Read only </span>
</dt> <dd>An integer representing the size of the buffer in sample-frames.</dd> </dl> <h3 id="Event_handlers">Event handlers</h3> <dl> <dt><a title="In this simple example, we declare both an AudioContext and an OfflineAudioContext object. We use the AudioContext to load an audio track via XHR (AudioContext.decodeAudioData), then the OfflineAudioContext to render the audio into an AudioBufferSourceNode and play the track through. After the offline audio graph is set up, you need to render it to an AudioBuffer using OfflineAudioContext.startRendering." href="offlineaudiocontext/oncomplete"><code>OfflineAudioContext.oncomplete</code></a></dt> <dd>Is an <a title="A possible way to get notified of Events of a particular type (such as click) for a given object is to specify an event handler using:" href="https://developer.mozilla.org/en-US/docs/Web/API/EventHandler"><code>EventHandler</code></a> called when processing is terminated, that is when the <code><a title="/en-US/docs/Web/Events/complete" href="https://developer.mozilla.org/en-US/docs/Web/Events/complete">complete</a></code> event (of type <a title="The Web Audio API OfflineAudioCompletionEvent interface represents events that occur when the processing of an OfflineAudioContext is terminated. The complete event implements this interface." href="offlineaudiocompletionevent"><code>OfflineAudioCompletionEvent</code></a>) is raised, after the event-based version of <a title="The startRendering() method of the OfflineAudioContext Interface starts rendering the audio graph, taking into account the current connections and the current scheduled changes." href="offlineaudiocontext/startrendering"><code>OfflineAudioContext.startRendering()</code></a> is used.</dd> </dl> <h2 id="Methods">Methods</h2> <p><em>Also implements methods from its parent, <a title="An AudioContext can be a target of events, therefore it implements the EventTarget interface." href="audiocontext"><code>AudioContext</code></a>, and <a title="EventTarget is an interface implemented by objects that can receive events and may have listeners for them." href="eventtarget"><code>EventTarget</code></a> too.</em></p> <dl> <dt><a title="Editorial review completed." href="offlineaudiocontext/resume"><code>OfflineAudioContext.resume()</code></a></dt> <dd>Resumes the progression of time in an audio context that has been suspended.</dd> <dt><a title="Editorial review completed." href="offlineaudiocontext/suspend"><code>OfflineAudioContext.suspend()</code></a></dt> <dd>Schedules a suspension of the time progression in the audio context at the specified time and returns a promise.</dd> <dt><a title="The startRendering() method of the OfflineAudioContext Interface starts rendering the audio graph, taking into account the current connections and the current scheduled changes." href="offlineaudiocontext/startrendering"><code>OfflineAudioContext.startRendering()</code></a></dt> <dd>Starts rendering the audio, taking into account the current connections and the current scheduled changes. This page covers both the event-based version and the promise-based version.</dd> </dl> <h2 id="Example">Example</h2> <p>In this simple example, we declare both an <a title="An AudioContext can be a target of events, therefore it implements the EventTarget interface." href="audiocontext"><code>AudioContext</code></a> and an <code>OfflineAudioContext</code> object. We use the <code>AudioContext</code> to load an audio track via XHR (<a title="This is the preferred method of creating an audio source for Web Audio API from an audio track." href="audiocontext/decodeaudiodata"><code>AudioContext.decodeAudioData</code></a>), then the <code>OfflineAudioContext</code> to render the audio into an <a title="The AudioBufferSourceNode interface represents an audio source consisting of in-memory audio data, stored in an AudioBuffer. It is an AudioNode that acts as an audio source." href="audiobuffersourcenode"><code>AudioBufferSourceNode</code></a> and play the track through. After the offline audio graph is set up, you need to render it to an <a title="Objects of these types are designed to hold small audio snippets, typically less than 45 s. For longer sounds, objects implementing the MediaElementAudioSourceNode are more suitable. The buffer contains data in the following format:  non-interleaved IEEE754 32-bit linear PCM with a nominal range between -1 and +1, that is, 32bits floating point buffer, with each samples between -1.0 and 1.0. If the AudioBuffer has multiple channels, they are stored in separate buffer." href="audiobuffer"><code>AudioBuffer</code></a> using <a title="The startRendering() method of the OfflineAudioContext Interface starts rendering the audio graph, taking into account the current connections and the current scheduled changes." href="offlineaudiocontext/startrendering"><code>OfflineAudioContext.startRendering</code></a>.</p> <p>When the <code>startRendering()</code> promise resolves, rendering has completed and the output <code>AudioBuffer</code> is returned out of the promise.</p> <p>At this point we create another audio context, create an <a title="The AudioBufferSourceNode interface represents an audio source consisting of in-memory audio data, stored in an AudioBuffer. It is an AudioNode that acts as an audio source." href="audiobuffersourcenode"><code>AudioBufferSourceNode</code></a> inside it, and set its buffer to be equal to the promise <code>AudioBuffer</code>. This is then played as part of a simple standard audio graph.</p> <div class="note"> <p><strong>Note</strong>: For a working example, see our <a href="https://mdn.github.io/webaudio-examples/offline-audio-context-promise/">offline-audio-context-promise</a> Github repo (see the <a href="https://github.com/mdn/webaudio-examples/tree/master/offline-audio-context-promise">source code</a> too.)</p> </div> <pre data-language="js">// define online and offline audio context

var audioCtx = new AudioContext();
var offlineCtx = new OfflineAudioContext(2,44100*40,44100);

source = offlineCtx.createBufferSource();

// use XHR to load an audio track, and
// decodeAudioData to decode it and OfflineAudioContext to render it

function getData() {
  request = new XMLHttpRequest();

  request.open('GET', 'viper.ogg', true);

  request.responseType = 'arraybuffer';

  request.onload = function() {
    var audioData = request.response;

    audioCtx.decodeAudioData(audioData, function(buffer) {
      myBuffer = buffer;
      source.buffer = myBuffer;
      source.connect(offlineCtx.destination);
      source.start();
      //source.loop = true;
      offlineCtx.startRendering().then(function(renderedBuffer) {
        console.log('Rendering completed successfully');
        var audioCtx = new (window.AudioContext || window.webkitAudioContext)();
        var song = audioCtx.createBufferSource();
        song.buffer = renderedBuffer;

        song.connect(audioCtx.destination);

        play.onclick = function() {
          song.start();
        }
      }).catch(function(err) {
          console.log('Rendering failed: ' + err);
          // Note: The promise should reject when startRendering is called a second time on an OfflineAudioContext
      });
    });
  }

  request.send();
}

// Run getData to start the process off

getData();</pre> <h2 id="Specifications">Specifications</h2> <table class="standard-table"> <tbody> <tr> <th scope="col">Specification</th> <th scope="col">Status</th> <th scope="col">Comment</th> </tr> <tr> <td><a hreflang="en" class="external" lang="en" href="https://webaudio.github.io/web-audio-api/#OfflineAudioContext">Web Audio API<br><small lang="en-US">The definition of 'OfflineAudioContext' in that specification.</small></a></td> <td><span class="spec-WD">Working Draft</span></td> <td>Initial definition</td> </tr> </tbody> </table> <h2 id="Browser_compatibility">Browser compatibility</h2>  <div id="compat-desktop"> <table class="compat-table"> <tbody> <tr> <th>Feature</th> <th>Chrome</th> <th>Edge</th> <th>Firefox (Gecko)</th> <th>Internet Explorer</th> <th>Opera</th> <th>Safari (WebKit)</th> </tr> <tr> <td>Basic support</td> <td>10.0<span title="prefix" class="inlineIndicator prefixBox prefixBoxInline"><a title="The name of this feature is prefixed with 'webkit' as this browser considers it experimental" href="https://developer.mozilla.org/en-US/docs/Web/Guide/Prefixes">webkit</a></span>
</td> <td><span title="Please update this with the earliest version of support." style="color: #888;">(Yes)</span></td> <td>
<a title="Released on 2013-10-29." href="https://developer.mozilla.org/en-US/Firefox/Releases/25">25.0</a> (25.0)</td> <td><span style="color: #f00;">No support</span></td> <td>15.0<span title="prefix" class="inlineIndicator prefixBox prefixBoxInline"><a title="The name of this feature is prefixed with 'webkit' as this browser considers it experimental" href="https://developer.mozilla.org/en-US/docs/Web/Guide/Prefixes">webkit</a></span><br> 22 (unprefixed)</td> <td>6.0<span title="prefix" class="inlineIndicator prefixBox prefixBoxInline"><a title="The name of this feature is prefixed with 'webkit' as this browser considers it experimental" href="https://developer.mozilla.org/en-US/docs/Web/Guide/Prefixes">webkit</a></span>
</td> </tr> <tr> <td>Promise-based <code>startRendering()</code>
</td> <td>42.0</td> <td><span title="Compatibility unknown; please update this." style="color: rgb(255, 153, 0);">?</span></td> <td>
<a title="Released on 2015-04-07." href="https://developer.mozilla.org/en-US/Firefox/Releases/37">37.0</a> (37.0)</td> <td><span title="Compatibility unknown; please update this." style="color: rgb(255, 153, 0);">?</span></td> <td><span title="Compatibility unknown; please update this." style="color: rgb(255, 153, 0);">?</span></td> <td><span title="Compatibility unknown; please update this." style="color: rgb(255, 153, 0);">?</span></td> </tr> <tr> <td>
<code>suspend()</code>, <code>resume()</code>
</td> <td>49.0</td> <td><span title="Compatibility unknown; please update this." style="color: rgb(255, 153, 0);">?</span></td> <td> </td> <td> </td> <td> </td> <td> </td> </tr> <tr> <td><code>length</code></td> <td>51.0</td> <td><span title="Compatibility unknown; please update this." style="color: rgb(255, 153, 0);">?</span></td> <td> </td> <td> </td> <td> </td> <td> </td> </tr> </tbody> </table> </div> <div id="compat-mobile"> <table class="compat-table"> <tbody> <tr> <th>Feature</th> <th>Android Webview</th> <th>Firefox Mobile (Gecko)</th> <th>Firefox OS</th> <th>Edge</th> <th>IE Mobile</th> <th>Opera Mobile</th> <th>Safari Mobile</th> <th>Chrome for Android</th> </tr> <tr> <td>Basic support</td> <td>33.0</td> <td>26.0</td> <td>1.2</td> <td><span title="Please update this with the earliest version of support." style="color: #888;">(Yes)</span></td> <td><span title="Compatibility unknown; please update this." style="color: rgb(255, 153, 0);">?</span></td> <td><span title="Compatibility unknown; please update this." style="color: rgb(255, 153, 0);">?</span></td> <td><span title="Compatibility unknown; please update this." style="color: rgb(255, 153, 0);">?</span></td> <td><span title="Please update this with the earliest version of support." style="color: #888;">(Yes)</span></td> </tr> <tr> <td>Promise-based <code>startRendering()</code>
</td> <td>42.0</td> <td>37.0</td> <td>2.2</td> <td><span title="Compatibility unknown; please update this." style="color: rgb(255, 153, 0);">?</span></td> <td><span title="Compatibility unknown; please update this." style="color: rgb(255, 153, 0);">?</span></td> <td><span title="Compatibility unknown; please update this." style="color: rgb(255, 153, 0);">?</span></td> <td><span title="Compatibility unknown; please update this." style="color: rgb(255, 153, 0);">?</span></td> <td>42.0</td> </tr> <tr> <td>
<code>suspend()</code>, <code>resume()</code>
</td> <td>49.0</td> <td> </td> <td> </td> <td><span title="Compatibility unknown; please update this." style="color: rgb(255, 153, 0);">?</span></td> <td> </td> <td> </td> <td> </td> <td>49.0</td> </tr> <tr> <td><code>length</code></td> <td>51.0</td> <td> </td> <td> </td> <td><span title="Compatibility unknown; please update this." style="color: rgb(255, 153, 0);">?</span></td> <td> </td> <td> </td> <td> </td> <td>51.0</td> </tr> </tbody> </table> </div> <h2 id="See_also">See also</h2> <ul> <li><a href="https://developer.mozilla.org/en-US/docs/Web_Audio_API/Using_Web_Audio_API">Using the Web Audio API</a></li> </ul><div class="_attribution">
  <p class="_attribution-p">
    <a href="https://developer.mozilla.org/en-US/docs/Web/API/OfflineAudioContext$edit" class="_attribution-link">Edit this page on MDN</a>
  </p>
</div>
<div class="_attribution">
  <p class="_attribution-p">
    &copy; 2005&ndash;2017 Mozilla Developer Network and individual contributors.<br>Licensed under the Creative Commons Attribution-ShareAlike License v2.5 or later.<br>
    <a href="https://developer.mozilla.org/en-US/docs/Web/API/OfflineAudioContext" class="_attribution-link">https://developer.mozilla.org/en-US/docs/Web/API/OfflineAudioContext</a>
  </p>
</div>
