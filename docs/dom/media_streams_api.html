<h1>Media Streams API</h1> <p>The <strong>Media Capture and Streams</strong> API, often called the <em>Media Stream API</em> or the <em>Stream API</em>, is an API related to <a title="/en-US/docs/WebRTC" href="https://developer.mozilla.org/en-US/docs/WebRTC">WebRTC</a> which supports streams of audio or video data, the methods for working with them, the constraints associated with the type of data, the success and error callbacks when using the data asynchronously, and the events that are fired during the process.</p> <h2 id="Basic_concepts">Basic concepts</h2> <p>The API is based on the manipulation of a <a title="The MediaStream interface represents a stream of media content. A stream consists of several tracks such as video or audio tracks. Each track is specified as an instance of MediaStreamTrack." href="mediastream"><code>MediaStream</code></a> object representing a flux of audio- or video-related data. See an example in <a title="/en-US/docs/WebRTC/taking_webcam_photos#Get_the_video" href="https://developer.mozilla.org/en-US/docs/WebRTC/taking_webcam_photos#Get_the_video">Get the video</a>.</p> <p>A <code>MediaStream</code> consists of zero or more <a title="The MediaStreamTrack interface represents a single media track within a stream; typically, these are audio or video tracks, but other track types may exist as well." href="mediastreamtrack"><code>MediaStreamTrack</code></a> objects, representing various audio or video <strong>tracks</strong>. Each <code>MediaStreamTrack</code> may have one or more <strong>channels</strong>. The channel represents the smallest unit of a media stream, such as an audio signal associated with a given speaker, like <em>left</em> or <em>right</em> in a stereo audio track.</p> <p><code>MediaStream</code> objects have a single <strong>input</strong> and a single <strong>output</strong>. A <code>MediaStream</code> object generated by <a title="The MediaDevices.getUserMedia() method prompts the user for permission to use one video and/or one audio input device such as a camera or screensharing and/or a microphone. If the user provides permission, then the returned Promise is resolved with the resulting MediaStream object. If the user denies permission, or media is not available, then the promise is rejected with PermissionDeniedError or NotFoundError respectively. Note that it is possible for the returned promise to neither resolve nor reject, as the user is not required to make a choice." href="mediadevices/getusermedia"><code>getUserMedia()</code></a> is called <em>local</em>, and has as its source input one of the user's cameras or microphones. A non-local <code>MediaStream</code> may be representing to a media element, like <a title="Use the HTML &lt;video&gt; element to embed video content in a document." href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/video"><code>&lt;video&gt;</code></a> or <a title="The HTML &lt;audio&gt; element is used to embed sound content in documents. It may contain one or more audio sources, represented using the src attribute or the &lt;source&gt; element; the browser will choose the most suitable one." href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/audio"><code>&lt;audio&gt;</code></a>, a stream originating over the network, and obtained via the WebRTC <a title="The RTCPeerConnection interface represents a WebRTC connection between the local computer and a remote peer. It provides methods to connect to a remote peer, maintain and monitor the connection, and close the connection once it's no longer needed." href="rtcpeerconnection"><code>RTCPeerConnection</code></a> API, or a stream created using the <a title="/en-US/docs/Web_Audio_API" href="https://developer.mozilla.org/en-US/docs/Web_Audio_API">Web Audio API</a> <a title="A MediaElementSourceNode has no inputs and exactly one output, and is created using the AudioContext.createMediaStreamSource method. The amount of channels in the output equals the number of channels in AudioMediaStreamTrack. If there is no valid media stream, then the number of output channels will be one silent channel." href="mediastreamaudiosourcenode"><code>MediaStreamAudioSourceNode</code></a>. The output of the <code>MediaStream</code> object is linked to a <strong>consumer</strong>. It can be a media elements, like <a title="The HTML &lt;audio&gt; element is used to embed sound content in documents. It may contain one or more audio sources, represented using the src attribute or the &lt;source&gt; element; the browser will choose the most suitable one." href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/audio"><code>&lt;audio&gt;</code></a> or <a title="Use the HTML &lt;video&gt; element to embed video content in a document." href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/video"><code>&lt;video&gt;</code></a>, the WebRTC <a title="The RTCPeerConnection interface represents a WebRTC connection between the local computer and a remote peer. It provides methods to connect to a remote peer, maintain and monitor the connection, and close the connection once it's no longer needed." href="rtcpeerconnection"><code>RTCPeerConnection</code></a> API or a <a title="/en-US/docs/Web_Audio_API" href="https://developer.mozilla.org/en-US/docs/Web_Audio_API">Web Audio API</a> <a title="Inherits properties from its parent, AudioNode." href="mediastreamaudiodestinationnode"><code>MediaStreamAudioDestinationNode</code></a>.</p> <h2 id="Reference">Reference</h2> <div class="index"> <ul> <li>
<code><a title="/en-US/docs/Web/Events/addtrack" href="https://developer.mozilla.org/en-US/docs/Web/Events/addtrack">addtrack</a></code> (event)</li> <li><a title="The documentation about this has not yet been written; please consider contributing!" href="https://developer.mozilla.org/en-US/docs/Web/API/AudioStreamTrack"><code>AudioStreamTrack</code></a></li> <li><a title="The BlobEvent interface represents events associated with a Blob. These blobs are typically, but not necessarily,  associated with media content." href="blobevent"><code>BlobEvent</code></a></li> <li>
<code><a title="/en-US/docs/Web/Events/ended" href="https://developer.mozilla.org/en-US/docs/Web/Events/ended">ended</a></code> (event)</li> <li><a title="The MediaStream interface represents a stream of media content. A stream consists of several tracks such as video or audio tracks. Each track is specified as an instance of MediaStreamTrack." href="mediastream"><code>MediaStream</code></a></li> <li><a title="The MediaStreamTrack interface represents a single media track within a stream; typically, these are audio or video tracks, but other track types may exist as well." href="mediastreamtrack"><code>MediaStreamTrack</code></a></li> <li><a title="The MediaStreamTrackEvent interface represents events which indicate that a MediaStream has had tracks added to or removed from the stream through calls to Media Stream API methods. These events are sent to the stream when these changes occur." href="mediastreamtrackevent"><code>MediaStreamTrackEvent</code></a></li> <li><a title="The documentation about this has not yet been written; please consider contributing!" href="https://developer.mozilla.org/en-US/docs/Web/API/MediaTrackCapabilities"><code>MediaTrackCapabilities</code></a></li> <li><a title="The MediaTrackConstraints dictionary is used to describe a set of capabilities and the value or values each can take on. A constraints dictionary is passed into applyConstraints() to allow a script to establish a set of exact (required) values or ranges and/or preferred values or ranges of values for the track, and the most recently-requested set of custom constraints can be retrieved by calling getConstraints()." href="mediatrackconstraints"><code>MediaTrackConstraints</code></a></li> <li><a title="The MediaTrackSettings dictionary is used to return the current values configured for each of a MediaStreamTrack's settings. These values will adhere as closely as possible to any constraints previously described using a MediaTrackConstraints object and set using applyConstraints(), and will adhere to the default constraints for any properties whose constraints haven't been changed, or whose customized constraints couldn't be matched." href="mediatracksettings"><code>MediaTrackSettings</code></a></li> <li><a title="The MediaTrackSupportedConstraints dictionary establishes the list of constrainable properties recognized by the user agent or browser in its implementation of the MediaStreamTrack object. An object conforming to MediaTrackSupportedConstraints is returned by MediaDevices.getSupportedConstraints()." href="mediatracksupportedconstraints"><code>MediaTrackSupportedConstraints</code></a></li> <li>
<code><a title="/en-US/docs/Web/Events/muted" href="https://developer.mozilla.org/en-US/docs/Web/Events/muted">muted</a></code> (event)</li> <li><a title="The documentation about this has not yet been written; please consider contributing!" href="https://developer.mozilla.org/en-US/docs/Web/API/navigatorUserMedia"><code>NavigatorUserMedia</code></a></li> <li><a title="The documentation about this has not yet been written; please consider contributing!" href="https://developer.mozilla.org/en-US/docs/Web/API/navigatorUserMediaError"><code>NavigatorUserMediaError</code></a></li> <li>
<code><a title="/en-US/docs/Web/Events/overconstrained" href="https://developer.mozilla.org/en-US/docs/Web/Events/overconstrained">overconstrained</a></code> (event)</li> <li>
<code><a title="/en-US/docs/Web/Events/removetrack" href="https://developer.mozilla.org/en-US/docs/Web/Events/removetrack">removetrack</a></code> (event)</li> <li>
<code><a title="/en-US/docs/Web/Events/started" href="https://developer.mozilla.org/en-US/docs/Web/Events/started">started</a></code> (event)</li> <li>
<code><a title="/en-US/docs/Web/Events/unmuted" href="https://developer.mozilla.org/en-US/docs/Web/Events/unmuted">unmuted</a></code> (event)</li> <li><a title="The URL interface represent an object providing static methods used for creating object URLs." href="url"><code>URL</code></a></li> <li><a title="The documentation about this has not yet been written; please consider contributing!" href="https://developer.mozilla.org/en-US/docs/Web/API/VideoStreamTrack"><code>VideoStreamTrack</code></a></li> </ul> </div> <h2 id="Guides_and_tutorials">Guides and tutorials</h2> <div class="row topicpage-table">  <div class="section"><dl>
<dt class="landingPageList"><a href="media_streams_api/constraints">Capabilities, constraints, and settings</a></dt>
<dd class="landingPageList">The twin concepts of <strong>constraints</strong> and <strong>capabilies</strong> let the browser and Web site or app exchange information about what <strong>constrainable properties</strong> the browser's implementation supports and what values it supports for each one. This article discusses capabilities and constraints, as well as media settings, and includes an example we call the <a href="#Example:_Constraint_exerciser">Example: Constraint exerciser</a>, which you can use to experiment with the results of different constraint sets being applied to the audio and video tracks coming from the computer's A/V input devices (such as its webcam and microphone).</dd>
</dl></div> </div> <h2 id="Browser_compatibility">Browser compatibility</h2>   <div id="compat-desktop"> <table class="compat-table"> <tbody> <tr> <th>Feature</th> <th>Chrome</th> <th>Firefox (Gecko)</th> <th>Microsoft Edge</th> <th>Internet Explorer</th> <th>Opera </th> <th>Safari (WebKit)</th> </tr> <tr> <td>Stream API </td> <td>21<span title="prefix" class="inlineIndicator prefixBox prefixBoxInline"><a title="The name of this feature is prefixed with 'webkit' as this browser considers it experimental" href="https://developer.mozilla.org/en-US/docs/Web/Guide/Prefixes">webkit</a></span> </td> <td>Nightly 18<span title="prefix" class="inlineIndicator prefixBox prefixBoxInline"><a title="The name of this feature is prefixed with 'moz' as this browser considers it experimental" href="https://developer.mozilla.org/en-US/docs/Web/Guide/Prefixes">moz</a></span> </td> <td><span title="Please update this with the earliest version of support." style="color: #888;">(Yes)</span></td> <td>
<span title="Compatibility unknown; please update this." style="color: rgb(255, 153, 0);">?</span> </td> <td>12</td> <td>
<span title="Compatibility unknown; please update this." style="color: rgb(255, 153, 0);">?</span> </td> </tr> </tbody> </table> </div> <div id="compat-mobile"> <table class="compat-table"> <tbody> <tr> <th>Feature</th> <th>Android</th> <th>Firefox Mobile (Gecko)</th> <th>IE Phone</th> <th>Opera Mobile</th> <th>Safari Mobile</th> </tr> <tr> <td>Stream API </td> <td>
<span style="color: #f00;">No support</span> </td> <td><span title="Compatibility unknown; please update this." style="color: rgb(255, 153, 0);">?</span></td> <td>
<span title="Compatibility unknown; please update this." style="color: rgb(255, 153, 0);">?</span> </td> <td>
<span style="color: #f00;">No support</span> </td> <td>
<span style="color: #f00;">No support</span> </td> </tr> </tbody> </table> </div> <p>Currently using WebRTC for accessing the camera is supported in Chrome, Opera and Firefox Nightly 18. Enabling WebRTC in Firefox Nightly requires you to set a flag in the configuration:</p> <ul> <li>Type "about:config" in the address bar and say yes that you want to make changes</li> <li>Find the "media.navigator.enabled" entry and set it to true</li> </ul> <h2 id="See_also">See also</h2> <ul> <li>
<a title="/en-US/docs/WebRTC" href="https://developer.mozilla.org/en-US/docs/WebRTC">WebRTC</a> - the introductory page to the API</li> <li><a title="The MediaDevices.getUserMedia() method prompts the user for permission to use one video and/or one audio input device such as a camera or screensharing and/or a microphone. If the user provides permission, then the returned Promise is resolved with the resulting MediaStream object. If the user denies permission, or media is not available, then the promise is rejected with PermissionDeniedError or NotFoundError respectively. Note that it is possible for the returned promise to neither resolve nor reject, as the user is not required to make a choice." href="mediadevices/getusermedia"><code>mediaDevices.getUserMedia()</code></a></li> <li>
<a href="https://developer.mozilla.org/en-US/docs/WebRTC/taking_webcam_photos">Taking webcam photos</a>: a demonstration and tutorial about using <code>getUserMedia()</code>.</li> </ul><div class="_attribution">
  <p class="_attribution-p">
    <a href="https://developer.mozilla.org/en-US/docs/Web/API/Media_Streams_API$edit" class="_attribution-link">Edit this page on MDN</a>
  </p>
</div>
<div class="_attribution">
  <p class="_attribution-p">
    &copy; 2005&ndash;2017 Mozilla Developer Network and individual contributors.<br>Licensed under the Creative Commons Attribution-ShareAlike License v2.5 or later.<br>
    <a href="https://developer.mozilla.org/en-US/docs/Web/API/Media_Streams_API" class="_attribution-link">https://developer.mozilla.org/en-US/docs/Web/API/Media_Streams_API</a>
  </p>
</div>
